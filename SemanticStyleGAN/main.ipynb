{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e507e688-d701-4033-83be-daa00076700a",
   "metadata": {},
   "source": [
    "# Semantic Style GAN を用いた表情モーフィング生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60260749-0c8f-4a6b-bf60-889239aca0e8",
   "metadata": {},
   "source": [
    "## 1. 事前学習済みモデルをダウンロードする\n",
    "学習済みモデルをpklファイルをダウンロードして`pretrained/` に配置する．`pretrained/`がない場合は自分で作成すること．<br>\n",
    "**DL : https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/CelebAMask-HQ-512x512.pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7e1c4-44f9-4992-99a9-2bf2a0cc94c1",
   "metadata": {},
   "source": [
    "## 2. 画像のサイズを事前学習済みモデルに合わせる\n",
    "CelebAMask-HQでは512x512サイズであるので，入力画像もそのサイズにリサイズしてBGR形式を作成する．<br>\n",
    "`images/`がない場合は作成し入力画像を配置して以下のプログラムを動かす．元画像が上書きされるので注意が必要．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5338e07-8b8f-4922-9edf-00a2cac20372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python resize512.py --indir images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d032f-2a42-4187-863c-833ca42b2948",
   "metadata": {},
   "source": [
    "## 3. 顔画像を中心に配置\n",
    "少しでも顔が中心でないく正しく推論できないため，画像を中心に配置する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd98fd7-3fb6-4946-aaa1-2e46a8929013",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python align_images.py --indir images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c827b30-7f58-4040-ab91-7ef3418fbab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. 出力フォルダを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531eb15-211e-4c04-bd5b-b8607a3ce6a0",
   "metadata": {},
   "source": [
    "invertするときの出力先は`results/inversion`，モーフィングの出力先は`results/interpolation`とする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b861885-d2ab-463a-97db-b0d6e954668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p results/inversion results/interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2b258-e500-4d11-bf10-47db05e3d919",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. 画像をモデルにinvertする（学習済みモデルに則して潜在変数を探索してファインチューニングをする）\n",
    "`images/`にある顔画像でをinvertして潜在変数(npy)を作成して，モデル(pt)をファインチューニングする．ファインチューニングはptiアルゴリズムを用いる．<br>\n",
    "潜在変数は`results/inversion/latent/`，ファインチューニング済みモデルは`results/inversion/weights/`に出力される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7496b-3fc5-42c4-bcf8-4b934953cffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=.:$PYTHONPATH python visualize/invert_pti.py --ckpt pretrained/CelebAMask-HQ-512x512.pt --imgdir images --outdir results/inversion --size 512 --step 3000  --finetune_step 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dec564-2645-472b-9168-f87a1dcd5e39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (5.2) 潜在変数を確認する\n",
    "潜在変数が本当に指定した顔に近づいているか確認する．<br>\n",
    "顔画像だけなら`results/inversion/recon/`，`results/inversion/recon_finetune/`に出力されるが，パーツごとの画像やスペクトルなどを調べるには以下を使う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484062fe-6069-4bd0-9aac-1f18ea9d27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python components_display.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e4b4f-9386-4ad0-8173-063067c8591a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.A 表情間モーフィングを作成する（線形補間）\n",
    "`/pretrained`にモデルを移してモーフィングを作成する．<br>\n",
    "逆順のモーフィングは作成されないのが逆再生で対応する．顔パーツ区間に分けながら潜在変数で線形モーフィングする．<br>\n",
    "線形モーフィングは $ I^M=\\alpha I^S+(1.0-\\alpha) I^T \\quad(0 \\leq \\alpha \\leq 1.0)$ ではあるが，$ I^S $，$ I^T $は単に画素値ではなく潜在変数であるこに留意する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893836a0-2116-4ed7-a2a3-5539452f72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -f results/inversion/weights/pti.pt pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588f1f4-8b25-48fb-af85-6f82e2f56d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python morphing_line.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cf268-2318-4f1b-96ed-18cc0d9def00",
   "metadata": {},
   "source": [
    "## 6.B 任意方向モーフィングを作成する（単体補間法）\n",
    "`/mat`にmatlabから表情弁別閾値楕円の中間ファイルを入れる．<br>\n",
    "中間ファイルは\n",
    "- thresholds.mat : 表情弁別閾値測定の画像のベクトルリスト\n",
    "- (expression).mat : 基本表情expressionの計量\n",
    "- points.mat : 全顔画像の心理物理空間の座標\n",
    "- points_info : 基本表情の添字と心理物理空間の座標を結びつけるファイル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d124c73-1e52-4794-ace4-1d7011913fc7",
   "metadata": {},
   "source": [
    "ベクトル（軸方向）$\\boldsymbol{e}$と頂点$\\boldsymbol{u}_1 \\dots \\boldsymbol{u}_6$からパラメータ$\\boldsymbol{\\gamma}$を得る．このパラメータは線形写像であるとき保存される．潜在空間は非線形であるが，リーマン多様体であるため局所的に保存される．\n",
    "$$\n",
    "\\begin{align*}\n",
    "\t\\boldsymbol{e} \n",
    "\t                    & =\\left(\\begin{array}{ccc}\n",
    "\t\t\t                             \\mid             &       & \\mid              \\\\\n",
    "\t\t\t                             \\boldsymbol{u}_1 & \\dots & \\boldsymbol{u}_6  \\\\\n",
    "\t\t\t                             \\mid             &       & \\mid\n",
    "\t\t                             \\end{array}\\right)\\left(\\begin{array}{l}\n",
    "\t\t\t                                                     c_1    \\\\\n",
    "\t\t\t                                                     \\vdots \\\\\n",
    "\t\t\t                                                     c_6\n",
    "\t\t                                                     \\end{array}\\right)                                                         \\\\\n",
    "\t                    & =: V \\boldsymbol{\\gamma}                                                                                           \\\\\n",
    "\tV                   & :=\\left(\\begin{array}{ccc}\n",
    "\t\t\t                              \\mid             &       & \\mid             \\\\\n",
    "\t\t\t                              \\boldsymbol{u}_1 & \\dots & \\boldsymbol{u}_6 \\\\\n",
    "\t\t\t                              \\mid             &       & \\mid\n",
    "\t\t                              \\end{array}\\right), \\boldsymbol{\\gamma}:=\\left(\\begin{array}{l}\n",
    "\t\t\t                                                                             c_1    \\\\\n",
    "\t\t\t                                                                             \\vdots \\\\\n",
    "\t\t\t                                                                             c_6\n",
    "\t\t                                                                             \\end{array}\\right)                                    \\\\\n",
    "\t\\boldsymbol{\\gamma} & =V^{-1} \\boldsymbol{e} \n",
    "\\end{align*}\n",
    "$$\n",
    "morphing_dict.pyで用いる表情や主軸の数などのパラメータはコードを修正すること．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d6e22-5592-4007-8290-80818967a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -f results/inversion/weights/pti.pt pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf54a71-624a-4554-96a0-667aaaf8fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python morphing_dict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7363f1-0d8b-452a-945f-9174c85492fc",
   "metadata": {},
   "source": [
    "## memo\n",
    "- 3において2をおこなわないと色空間の影響で上手に配置できないときがある．\n",
    "- 6.Bにおいて表情弁別閾値楕円の測定するmatlabファイルは公開していないので，それでも使いたい場合は自分の使いたいデータ用に変更すること．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
