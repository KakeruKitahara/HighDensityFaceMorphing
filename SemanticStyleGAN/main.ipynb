{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e507e688-d701-4033-83be-daa00076700a",
   "metadata": {},
   "source": [
    "# Semantic Style GAN のモーフィング生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60260749-0c8f-4a6b-bf60-889239aca0e8",
   "metadata": {},
   "source": [
    "## 1. 事前学習済みモデルをダウンロードする\n",
    "学習済みモデルをpklファイルをダウンロードして，`pretrained/` に配置する．**DL : https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/CelebAMask-HQ-512x512.pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7e1c4-44f9-4992-99a9-2bf2a0cc94c1",
   "metadata": {},
   "source": [
    "## 2. 画像のサイズを事前学習済みモデルに合わせる\n",
    "CelebAMask-HQでは512x512サイズであるので，入力画像もそのサイズにリサイズする．入力画像を`images/`に配置して以下のプログラムを動かす．元画像が上書きされるので注意が必要．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5338e07-8b8f-4922-9edf-00a2cac20372",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python resize512.py python resize512.py --input images/*.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2b258-e500-4d11-bf10-47db05e3d919",
   "metadata": {},
   "source": [
    "## 3. 画像をモデルにinvertする（学習済みモデルに則して潜在変数を探索してファインチューニングをする．）\n",
    "`images/`にある顔画像を全通りinvertする．従って，ある顔画像でinvertして，それでファインチューニングしたモデルを用いて別の顔画像で更にファインチューニングをする．顔画像は順不同なので${}_n C_2$個のファインチューニング済みモデルが作成される．潜在変数は`results/inversion/latent/*-*/`，ファインチューニング済みモデルは`/pretrained`に出力される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79416d78-be9b-48c6-aace-f5e5ed08a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverting from CelebAMask-HQ-512x512.pt ...\n",
      "Namespace(batch_size=1, ckpt='pretrained/CelebAMask-HQ-512x512.pt', finetune_step=300, imgdir='images', lambda_lpips=1.0, lambda_mean=1.0, lambda_mse=0.1, lr=0.1, lr_g=0.0001, no_noises=True, noise_regularize=10, original_ckpt_path='pretrained/CelebAMask-HQ-512x512.pt', outdir='results/inversion', save_steps=False, size=512, step=400, truncation=1, w_plus=True)\n",
      "Loading model ...\n",
      "Initializing model with arguments:\n",
      "{'aug': False,\n",
      " 'base_layers': 2,\n",
      " 'batch': 8,\n",
      " 'channel_multiplier': 2,\n",
      " 'checkpoint_dir': 'output/celeba-512',\n",
      " 'ckpt': None,\n",
      " 'coarse_channel': 512,\n",
      " 'coarse_size': 64,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset': 'dataset/lmdb_celebamaskhq_512',\n",
      " 'depth_layers': 6,\n",
      " 'detach_texture': False,\n",
      " 'distributed': True,\n",
      " 'g_reg_every': 4,\n",
      " 'inception': 'cache/cache_fid_celebahq_512_new.pkl',\n",
      " 'iter': 800000,\n",
      " 'lambda_mask': 100.0,\n",
      " 'latent': 512,\n",
      " 'local_channel': 64,\n",
      " 'local_layers': 10,\n",
      " 'local_rank': 0,\n",
      " 'lr': 0.002,\n",
      " 'min_feat_size': 16,\n",
      " 'mixing': 0.3,\n",
      " 'n_gpu': 4,\n",
      " 'n_mlp': 8,\n",
      " 'n_sample': 16,\n",
      " 'num_workers': 8,\n",
      " 'path_batch_shrink': 2,\n",
      " 'path_regularize': 0.5,\n",
      " 'r1_img': 10,\n",
      " 'r1_seg': 1000,\n",
      " 'residual_refine': True,\n",
      " 'save_every': 10000,\n",
      " 'seg_dim': 13,\n",
      " 'size': 512,\n",
      " 'start_iter': 20000,\n",
      " 'transparent_dims': (10, 12),\n",
      " 'viz_every': 2000}\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "model: CelebAMask-HQ-512x512, image: AN\n",
      "perc: 0.1323 noise: 1.0001 mse: 0.0189  latent: 0.0432: 100%|#| 400/400 [02:02<0\n",
      "perc: 0.0258 mse: 0.0026: 100%|###############| 300/300 [01:51<00:00,  2.70it/s]\n",
      "model: CelebAMask-HQ-512x512, image: DI\n",
      "perc: 0.1372 noise: 1.0001 mse: 0.0173  latent: 0.0343: 100%|#| 400/400 [02:02<0\n",
      "perc: 0.0317 mse: 0.0031: 100%|###############| 300/300 [01:50<00:00,  2.72it/s]\n",
      "model: CelebAMask-HQ-512x512, image: FE\n",
      "perc: 0.1016 noise: 1.0001 mse: 0.0117  latent: 0.0471: 100%|#| 400/400 [02:01<0\n",
      "perc: 0.0213 mse: 0.0016: 100%|###############| 300/300 [01:51<00:00,  2.70it/s]\n",
      "Inverting from AN.pt ...\n",
      "Namespace(batch_size=1, ckpt='results/inversion/weights/AN.pt', finetune_step=300, imgdir='images', lambda_lpips=1.0, lambda_mean=1.0, lambda_mse=0.1, lr=0.1, lr_g=0.0001, no_noises=True, noise_regularize=10, original_ckpt_path='pretrained/CelebAMask-HQ-512x512.pt', outdir='results/inversion', save_steps=False, size=512, step=400, truncation=1, w_plus=True)\n",
      "Loading model ...\n",
      "Initializing model with arguments:\n",
      "{'aug': False,\n",
      " 'base_layers': 2,\n",
      " 'batch': 8,\n",
      " 'channel_multiplier': 2,\n",
      " 'checkpoint_dir': 'output/celeba-512',\n",
      " 'ckpt': None,\n",
      " 'coarse_channel': 512,\n",
      " 'coarse_size': 64,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset': 'dataset/lmdb_celebamaskhq_512',\n",
      " 'depth_layers': 6,\n",
      " 'detach_texture': False,\n",
      " 'distributed': True,\n",
      " 'g_reg_every': 4,\n",
      " 'inception': 'cache/cache_fid_celebahq_512_new.pkl',\n",
      " 'iter': 800000,\n",
      " 'lambda_mask': 100.0,\n",
      " 'latent': 512,\n",
      " 'local_channel': 64,\n",
      " 'local_layers': 10,\n",
      " 'local_rank': 0,\n",
      " 'lr': 0.002,\n",
      " 'min_feat_size': 16,\n",
      " 'mixing': 0.3,\n",
      " 'n_gpu': 4,\n",
      " 'n_mlp': 8,\n",
      " 'n_sample': 16,\n",
      " 'num_workers': 8,\n",
      " 'path_batch_shrink': 2,\n",
      " 'path_regularize': 0.5,\n",
      " 'r1_img': 10,\n",
      " 'r1_seg': 1000,\n",
      " 'residual_refine': True,\n",
      " 'save_every': 10000,\n",
      " 'seg_dim': 13,\n",
      " 'size': 512,\n",
      " 'start_iter': 20000,\n",
      " 'transparent_dims': (10, 12),\n",
      " 'viz_every': 2000}\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "model: AN, image: AN\n",
      "same skip\n",
      "model: AN, image: DI\n",
      "perc: 0.0795 noise: 1.0001 mse: 0.0094  latent: 0.0309: 100%|#| 400/400 [02:01<0\n",
      "perc: 0.0219 mse: 0.0018: 100%|###############| 300/300 [01:49<00:00,  2.75it/s]\n",
      "model: AN, image: FE\n",
      "perc: 0.0679 noise: 1.0001 mse: 0.0048  latent: 0.0437: 100%|#| 400/400 [02:00<0\n",
      "perc: 0.0178 mse: 0.0012: 100%|###############| 300/300 [01:48<00:00,  2.75it/s]\n",
      "Inverting from DI.pt ...\n",
      "Namespace(batch_size=1, ckpt='results/inversion/weights/DI.pt', finetune_step=300, imgdir='images', lambda_lpips=1.0, lambda_mean=1.0, lambda_mse=0.1, lr=0.1, lr_g=0.0001, no_noises=True, noise_regularize=10, original_ckpt_path='pretrained/CelebAMask-HQ-512x512.pt', outdir='results/inversion', save_steps=False, size=512, step=400, truncation=1, w_plus=True)\n",
      "Loading model ...\n",
      "Initializing model with arguments:\n",
      "{'aug': False,\n",
      " 'base_layers': 2,\n",
      " 'batch': 8,\n",
      " 'channel_multiplier': 2,\n",
      " 'checkpoint_dir': 'output/celeba-512',\n",
      " 'ckpt': None,\n",
      " 'coarse_channel': 512,\n",
      " 'coarse_size': 64,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset': 'dataset/lmdb_celebamaskhq_512',\n",
      " 'depth_layers': 6,\n",
      " 'detach_texture': False,\n",
      " 'distributed': True,\n",
      " 'g_reg_every': 4,\n",
      " 'inception': 'cache/cache_fid_celebahq_512_new.pkl',\n",
      " 'iter': 800000,\n",
      " 'lambda_mask': 100.0,\n",
      " 'latent': 512,\n",
      " 'local_channel': 64,\n",
      " 'local_layers': 10,\n",
      " 'local_rank': 0,\n",
      " 'lr': 0.002,\n",
      " 'min_feat_size': 16,\n",
      " 'mixing': 0.3,\n",
      " 'n_gpu': 4,\n",
      " 'n_mlp': 8,\n",
      " 'n_sample': 16,\n",
      " 'num_workers': 8,\n",
      " 'path_batch_shrink': 2,\n",
      " 'path_regularize': 0.5,\n",
      " 'r1_img': 10,\n",
      " 'r1_seg': 1000,\n",
      " 'residual_refine': True,\n",
      " 'save_every': 10000,\n",
      " 'seg_dim': 13,\n",
      " 'size': 512,\n",
      " 'start_iter': 20000,\n",
      " 'transparent_dims': (10, 12),\n",
      " 'viz_every': 2000}\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "model: DI, image: AN\n",
      "inverse skip\n",
      "model: DI, image: DI\n",
      "same skip\n",
      "model: DI, image: FE\n",
      "perc: 0.0795 noise: 1.0001 mse: 0.0085  latent: 0.0345: 100%|#| 400/400 [01:56<0\n",
      "perc: 0.0181 mse: 0.0013: 100%|###############| 300/300 [01:47<00:00,  2.78it/s]\n",
      "Inverting from FE.pt ...\n",
      "Namespace(batch_size=1, ckpt='results/inversion/weights/FE.pt', finetune_step=300, imgdir='images', lambda_lpips=1.0, lambda_mean=1.0, lambda_mse=0.1, lr=0.1, lr_g=0.0001, no_noises=True, noise_regularize=10, original_ckpt_path='pretrained/CelebAMask-HQ-512x512.pt', outdir='results/inversion', save_steps=False, size=512, step=400, truncation=1, w_plus=True)\n",
      "Loading model ...\n",
      "Initializing model with arguments:\n",
      "{'aug': False,\n",
      " 'base_layers': 2,\n",
      " 'batch': 8,\n",
      " 'channel_multiplier': 2,\n",
      " 'checkpoint_dir': 'output/celeba-512',\n",
      " 'ckpt': None,\n",
      " 'coarse_channel': 512,\n",
      " 'coarse_size': 64,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset': 'dataset/lmdb_celebamaskhq_512',\n",
      " 'depth_layers': 6,\n",
      " 'detach_texture': False,\n",
      " 'distributed': True,\n",
      " 'g_reg_every': 4,\n",
      " 'inception': 'cache/cache_fid_celebahq_512_new.pkl',\n",
      " 'iter': 800000,\n",
      " 'lambda_mask': 100.0,\n",
      " 'latent': 512,\n",
      " 'local_channel': 64,\n",
      " 'local_layers': 10,\n",
      " 'local_rank': 0,\n",
      " 'lr': 0.002,\n",
      " 'min_feat_size': 16,\n",
      " 'mixing': 0.3,\n",
      " 'n_gpu': 4,\n",
      " 'n_mlp': 8,\n",
      " 'n_sample': 16,\n",
      " 'num_workers': 8,\n",
      " 'path_batch_shrink': 2,\n",
      " 'path_regularize': 0.5,\n",
      " 'r1_img': 10,\n",
      " 'r1_seg': 1000,\n",
      " 'residual_refine': True,\n",
      " 'save_every': 10000,\n",
      " 'seg_dim': 13,\n",
      " 'size': 512,\n",
      " 'start_iter': 20000,\n",
      " 'transparent_dims': (10, 12),\n",
      " 'viz_every': 2000}\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "model: FE, image: AN\n",
      "inverse skip\n",
      "model: FE, image: DI\n",
      "inverse skip\n",
      "model: FE, image: FE\n",
      "same skip\n"
     ]
    }
   ],
   "source": [
    "!python pair_inverting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70dd9a-a720-4d32-9583-7379fe84b3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
