{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e507e688-d701-4033-83be-daa00076700a",
   "metadata": {},
   "source": [
    "# Semantic Style GAN のモーフィング生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60260749-0c8f-4a6b-bf60-889239aca0e8",
   "metadata": {},
   "source": [
    "## 1. 事前学習済みモデルをダウンロードする\n",
    "学習済みモデルをpklファイルをダウンロードして，`pretrained/` に配置する．**DL : https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/CelebAMask-HQ-512x512.pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7e1c4-44f9-4992-99a9-2bf2a0cc94c1",
   "metadata": {},
   "source": [
    "## 2. 画像のサイズを事前学習済みモデルに合わせる\n",
    "CelebAMask-HQでは512x512サイズであるので，入力画像もそのサイズにリサイズする．`images/`を作成して，入力画像を配置して以下のプログラムを動かす．元画像が上書きされるので注意が必要．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5338e07-8b8f-4922-9edf-00a2cac20372",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python resize512.py --indir images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2b258-e500-4d11-bf10-47db05e3d919",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. 画像をモデルにinvertする（学習済みモデルに則して潜在変数を探索してファインチューニングをする．）\n",
    "`images/`にある顔画像を全通りinvertする．従って，ある顔画像でinvertして，それでファインチューニングしたモデルを用いて別の顔画像で更にファインチューニングをする．顔画像は順不同なので${}_n C_2$個のファインチューニング済みモデルが作成される．潜在変数は`results/inversion/latent/*-*/`，ファインチューニング済みモデルは`/pretrained`に出力される．やり直すときは`/pretrained`のptファイルを削除しておくこと．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7ffba-83bb-4cdf-9f90-9dcbd57146a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1. 学習済みモデルを用いて全ての顔画像に対してinvertする\n",
    "作成されたファインチューニング済みモデルは`/results/inversion/weights`に保存される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a52d149-1a15-46a3-9e4a-d4923c455e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, ckpt='pretrained/CelebAMask-HQ-512x512.pt', finetune_step=300, imgdir='images', lambda_lpips=1.0, lambda_mean=1.0, lambda_mse=0.1, lr=0.1, lr_g=0.0001, no_noises=True, noise_regularize=10, original_ckpt_path='pretrained/CelebAMask-HQ-512x512.pt', outdir='results/inversion', save_steps=False, size=512, step=400, truncation=1, w_plus=True)\n",
      "Loading model ...\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "model: CelebAMask-HQ-512x512, image: SA\n",
      "perc: 0.1202 noise: 1.0001 mse: 0.0164  latent: 0.0329: 100%|#| 400/400 [01:49<0\n",
      "perc: 0.0259 mse: 0.0024: 100%|###############| 300/300 [01:40<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=.:$PYTHONPATH python visualize/invert.py --ckpt pretrained/CelebAMask-HQ-512x512.pt --imgdir images --outdir results/inversion --size 512 --finetune_step 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dec564-2645-472b-9168-f87a1dcd5e39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (3.2.) 潜在変数を確認する\n",
    "潜在変数が本当に指定した顔に近づいているか，顔表情，マスク，スペクトルをを確認する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484062fe-6069-4bd0-9aac-1f18ea9d27f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display SA...\n",
      "Loading model ...\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "Generating images...\n"
     ]
    }
   ],
   "source": [
    "!python components_display.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c66ccc-f835-4040-b479-56fdabf24737",
   "metadata": {},
   "source": [
    "### 3.3. ファインチューニングした全てのモデルを用いて全ての顔画像に対してinvertする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79416d78-be9b-48c6-aace-f5e5ed08a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverting from SA.pt ...\n",
      "Namespace(batch_size=1, ckpt='results/inversion/weights/SA.pt', finetune_step=300, imgdir='images', lambda_lpips=1.0, lambda_mean=1.0, lambda_mse=0.1, lr=0.1, lr_g=0.0001, no_noises=True, noise_regularize=10, original_ckpt_path='pretrained/CelebAMask-HQ-512x512.pt', outdir='results/inversion', save_steps=False, size=512, step=400, truncation=1, w_plus=True)\n",
      "Loading model ...\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "model: SA, image: HA\n",
      "perc: 0.0937 noise: 1.0001 mse: 0.0086  latent: 0.0414: 100%|#| 400/400 [01:56<0\n",
      "perc: 0.0243 mse: 0.0023: 100%|###############| 300/300 [01:46<00:00,  2.81it/s]\n",
      "model: SA, image: SA\n",
      "perc: 0.0295 noise: 1.0001 mse: 0.0027  latent: 0.0260: 100%|#| 400/400 [01:56<0\n",
      "model: SA, image: SU\n",
      "perc: 0.0607 noise: 1.0001 mse: 0.0101  latent: 0.0296: 100%|#| 400/400 [01:56<0\n",
      "perc: 0.0159 mse: 0.0015: 100%|###############| 300/300 [01:45<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "!python pair_inverting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e4b4f-9386-4ad0-8173-063067c8591a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. モーフィングを作成する\n",
    "`/pretrained`のモデル順にモーフィングを作成する．逆順のモーフィングは作成されないのが逆再生で対応できる．顔パーツ区間に分けながら潜在変数で線形モーフィングする．線形モーフィングは $ I^M=\\alpha I^S+(1.0-\\alpha) I^T \\quad(0 \\leq \\alpha \\leq 1.0)$ ではあるが，$ I^S $，$ I^T $は単に画素値ではなく潜在変数であるこに留意する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b70dd9a-a720-4d32-9583-7379fe84b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morphing SA-HA\n",
      "Loading model ...\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "Generating original image ...\n",
      "Generating morphing SA -> HA\n",
      "100%|#########################################| 100/100 [00:52<00:00,  1.92it/s]\n",
      "Morphing SA-SU\n",
      "Loading model ...\n",
      "n_latent: 28, n_latent_expand: 130\n",
      "Generating original image ...\n",
      "Generating morphing SA -> SU\n",
      "100%|#########################################| 100/100 [00:40<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "!python morphing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d6606-2cf7-4f36-9d48-960235af5f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
