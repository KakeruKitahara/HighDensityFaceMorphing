{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e507e688-d701-4033-83be-daa00076700a",
   "metadata": {},
   "source": [
    "# Semantic Style GAN のモーフィング生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60260749-0c8f-4a6b-bf60-889239aca0e8",
   "metadata": {},
   "source": [
    "## 1. 事前学習済みモデルをダウンロードする\n",
    "学習済みモデルをpklファイルをダウンロードして，`pretrained/` に配置する．**DL : https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/CelebAMask-HQ-512x512.pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7e1c4-44f9-4992-99a9-2bf2a0cc94c1",
   "metadata": {},
   "source": [
    "## 2. 画像のサイズを事前学習済みモデルに合わせる\n",
    "CelebAMask-HQでは512x512サイズであるので，入力画像もそのサイズにリサイズする．`images/`を作成して，入力画像を配置して以下のプログラムを動かす．元画像が上書きされるので注意が必要．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5338e07-8b8f-4922-9edf-00a2cac20372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python resize512.py --indir images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2b258-e500-4d11-bf10-47db05e3d919",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. 画像をモデルにinvertする（学習済みモデルに則して潜在変数を探索してファインチューニングをする．）\n",
    "`images/`にある顔画像を全通りinvertする．従って，ある顔画像でinvertして，それでファインチューニングしたモデルを用いて別の顔画像で更にファインチューニングをする．顔画像は順不同なので${}_n C_2$個のファインチューニング済みモデルが作成される．潜在変数は`results/inversion/latent/*-*/`，ファインチューニング済みモデルは`/pretrained`に出力される．やり直すときは`/pretrained`のptファイルを削除しておくこと．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7ffba-83bb-4cdf-9f90-9dcbd57146a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1. 学習済みモデルを用いて全ての顔画像に対してinvertする\n",
    "作成されたファインチューニング済みモデルは`/results/inversion/weights`に保存される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52d149-1a15-46a3-9e4a-d4923c455e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!PYTHONPATH=.:$PYTHONPATH python visualize/invert.py --ckpt pretrained/CelebAMask-HQ-512x512.pt --imgdir images --outdir results/inversion --size 512 --finetune_step 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dec564-2645-472b-9168-f87a1dcd5e39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (3.2.) 潜在変数を確認する\n",
    "潜在変数が本当に指定した顔に近づいているか，顔表情，マスク，スペクトルをを確認する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484062fe-6069-4bd0-9aac-1f18ea9d27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python components_display.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c66ccc-f835-4040-b479-56fdabf24737",
   "metadata": {},
   "source": [
    "### 3.3. ファインチューニングした全てのモデルを用いて全ての顔画像に対してinvertする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79416d78-be9b-48c6-aace-f5e5ed08a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pair_inverting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e4b4f-9386-4ad0-8173-063067c8591a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. モーフィングを作成する\n",
    "`/pretrained`のモデル順にモーフィングを作成する．逆順のモーフィングは作成されないのが逆再生で対応できる．顔パーツ区間に分けながら潜在変数で線形モーフィングする．線形モーフィングは $ I^M=\\alpha I^S+(1.0-\\alpha) I^T \\quad(0 \\leq \\alpha \\leq 1.0)$ ではあるが，$ I^S $，$ I^T $は単に画素値ではなく潜在変数であるこに留意する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70dd9a-a720-4d32-9583-7379fe84b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python morphing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d6606-2cf7-4f36-9d48-960235af5f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
